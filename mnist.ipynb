{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Downloading and loading the dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3813fd84b867ae8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# torchvision.datasets.MNIST(root=\"./mnist_data/\", download=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12e77bf99bf53fe5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# image size and total number of images \n",
    "# as described in http://yann.lecun.com/exdb/mnist/\n",
    "image_size = 28\n",
    "total_images = 60000\n",
    "\n",
    "file_path = \"./mnist_data/MNIST/raw/\"\n",
    "\n",
    "with gzip.open(f\"{file_path}train-images-idx3-ubyte.gz\", \"r\") as f:\n",
    "    # the first 16 bytes is the header, .read(16) effectively skips it\n",
    "    f.read(16) \n",
    "    \n",
    "    # defining how to read the data \n",
    "    buf = f.read(image_size * image_size * total_images)\n",
    "    training_images = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "    \n",
    "    # the dimensions here are should actually be \n",
    "    # (number of images, channels, image height, image width)\n",
    "    # but I am loading it for plotting the image using numpy \n",
    "    # and I reshaped it later for torch\n",
    "    training_images = training_images.reshape(total_images, image_size, image_size, 1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d703c3a1d5ada66"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with gzip.open(f\"{file_path}train-labels-idx1-ubyte.gz\", \"r\") as f:\n",
    "    # the first 8 bytes is the header, skipping it\n",
    "    f.read(8)\n",
    "    buf = f.read()\n",
    "    training_labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int_)\n",
    "\n",
    "print(training_labels)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7320cbe7de941d75"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plotting the image\n",
    "image = training_images[3]\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a33400c734ee357"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# converting the numpy arrays to tensors\n",
    "training_images = torch.from_numpy(training_images)\n",
    "\n",
    "# changing the dimension to match (number of images, channels, image height, image width)\n",
    "training_images = torch.reshape(training_images, (60000, 1, 28, 28))\n",
    "training_labels = torch.from_numpy(training_labels)\n",
    "\n",
    "# normalizing values between 0 to 1\n",
    "training_images /= 255.0"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0db910c9390f783"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# checking if the training labels look okay\n",
    "training_labels[:10]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "175eb1f4d7edddc3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# checking if the shape is fine\n",
    "training_images.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c54b02844df9c1b0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plotting the tensor as an image\n",
    "# .squeeze() removes dimension = 1 which represents the channel\n",
    "image = training_images[0].squeeze()\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf3317f3223d6341"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# this block of code is mildly modified but uses the same code as the pytorch tutorial \n",
    "# https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    \n",
    "    # the transpose re-arranges the dimensions to H x W x channel\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# here, batch size controls how many images will be printed\n",
    "trainloader_for_plot = torch.utils.data.DataLoader(\n",
    "    training_images, \n",
    "    batch_size=6\n",
    ")\n",
    "dataiter = iter(trainloader_for_plot)\n",
    "images = next(dataiter)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d756d2abfb5cb50"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining the CNN"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-18T20:44:31.709086Z",
     "start_time": "2024-06-18T20:44:31.671844Z"
    }
   },
   "id": "d0f63e31153aad34"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# a slightly modified version of the convolutional net defined in the pytorch tutorial \n",
    "# https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5) \n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ad65425210e74ba"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# printing the total number of parameters\n",
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "\n",
    "# the weight of first layer (self.conv1)\n",
    "print(params[0].size())  # conv1's .weight"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28ab101241582942"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(training_images[0].shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a862e4a340ab0110"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# running the NN on one example\n",
    "input = training_images[0].unsqueeze(0)\n",
    "out = net(input)\n",
    "print(out)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5415b9ed561e93c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# defining the loss function and optimization routine\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88081c4b196837c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# prepping data using TensorDataset and DataLoader\n",
    "dataset = TensorDataset(training_images, training_labels)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# looping over the number of training runs\n",
    "for epoch in range(15):\n",
    "    \n",
    "    running_loss = 0\n",
    "    for n, data in enumerate(dataloader):\n",
    "        inputs, labels = data\n",
    "\n",
    "        # setting the parameter gradients back to zero\n",
    "        # running the one example above affected the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # printing the loss for every 2000 mini-batches\n",
    "        if n % 2000 == 1999:\n",
    "            print(f'[{epoch + 1}, {n + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            \n",
    "            running_loss = 0\n",
    "\n",
    "print('Finished Training')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9f36db05b4ffc21"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing the performance of the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6f1a0b1bc0493af"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Reading the test data similar to how the training data was loaded"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d4d7a3c323d9e0e5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_size = 28\n",
    "total_images_testing = 10000\n",
    "file_path = \"./mnist_data/MNIST/raw/\"\n",
    "\n",
    "with gzip.open(f\"{file_path}t10k-images-idx3-ubyte.gz\", \"r\") as f:\n",
    "    f.read(16)\n",
    "    buf = f.read(image_size * image_size * total_images_testing)\n",
    "    testing_images = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "    testing_images = testing_images.reshape(total_images_testing, 1, image_size, image_size)\n",
    "\n",
    "with gzip.open(f\"{file_path}t10k-labels-idx1-ubyte.gz\", \"r\") as f:\n",
    "    f.read(8)\n",
    "    buf = f.read()\n",
    "    testing_labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int_)\n",
    "\n",
    "testing_images = torch.from_numpy(testing_images)\n",
    "testing_labels = torch.from_numpy(testing_labels)\n",
    "\n",
    "training_images /= 255.0"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d700de6652a1604"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "testset = TensorDataset(testing_images, testing_labels)\n",
    "testloader = DataLoader(testset, batch_size=4)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "168236cdbc999152"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# checking correctness (copy-pasted from the tutorial)\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        \n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        \n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7ce7c613b87c049"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3a4fcc058efaed44"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
